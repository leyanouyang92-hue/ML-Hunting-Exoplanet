# app.py â€”â€” Streamlit å‰ç«¯ï¼Œå¤ç”¨ src/ å†…æ¨¡å—
import io
import numpy as np
import pandas as pd
import streamlit as st
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, precision_recall_curve

from src.harmonize import harmonize_table
from src.config import CANON_ORDER
from src.visualize import build_dashboard_fig

from src.ui import inject_css, title_bar, upload_card, kpi_grid, render_universe_html
from streamlit.components.v1 import html


# ---------------- UI --------------
st.set_page_config(page_title="Exoplanet ML Explorer", layout="wide")
inject_css()
title_bar()


# ---------------- è¯»ä¸Šä¼ æ–‡ä»¶ --------------
def read_uploaded(file):
    if file is None:
        return None
    name = file.name.lower()
    data = file.read()
    if name.endswith((".xls", ".xlsx")):
        return pd.read_excel(io.BytesIO(data))
    # CSV/TSVï¼ˆå¸¦ # æ³¨é‡Šä¹Ÿå…¼å®¹ï¼‰
    try:
        return pd.read_csv(io.BytesIO(data), comment="#", low_memory=False)
    except Exception:
        return pd.read_csv(io.BytesIO(data), sep=None, engine="python", comment="#", low_memory=False)


with st.sidebar:
    st.header("1) Data Upload")
    koi_up  = upload_card("Kepler cumulative", key="koi",
                          types=["csv", "tsv", "txt", "xlsx", "xls"])
    tess_up = upload_card("TESS TOI",         key="tess",
                          types=["csv", "tsv", "txt", "xlsx", "xls"])
    k2_up   = upload_card("K2 P&C",           key="k2",
                          types=["csv", "tsv", "txt", "xlsx", "xls"])

    st.header("2) Training parameters")
    test_size    = st.slider("Test size", 0.1, 0.4, 0.2, 0.05)
    n_estimators = st.slider("RF trees", 100, 1000, 400, 50)
    rs           = st.number_input("Random state", 0, 9999, 42, step=1)


# ---------------- ç»Ÿä¸€ä¸åˆå¹¶ --------------
dfs = []
for up, mission in [(koi_up, "Kepler"), (tess_up, "TESS"), (k2_up, "K2")]:
    raw = read_uploaded(up)
    if raw is not None:
        h = harmonize_table(raw, mission)  # è¿™é‡Œå·²åŒ…å« ra/dec/dist_raw çš„ä¿ç•™
        st.sidebar.write(f"{mission}: {len(h)} row | with label: {h['label'].notna().sum()}")
        dfs.append(h)

if not dfs:
    st.info("ğŸ‘‰ At least one data file must be uploaded on the left side.ï¼ˆKepler/TESS/K2ï¼‰ã€‚")
    st.stop()

df_all = pd.concat(dfs, ignore_index=True)

# 3D å®‡å®™è§†å›¾ï¼ˆä½¿ç”¨å…¨ä½“åˆå¹¶æ•°æ®ï¼›_to_xyz ä¼šä¼˜å…ˆç”¨ RA/DECï¼‰
html(render_universe_html(df_all, color_by="label",
                          max_points=6000, point_size=1.8),
     height=560)


# ---------------- è®­ç»ƒç”¨æ•°æ®ï¼ˆç¨³å¥ç‰ˆï¼›ä¸ä½¿ç”¨è·ç¦»ä½œä¸ºç‰¹å¾ï¼‰ ----------------
from sklearn.impute import SimpleImputer

# åªä¿ç•™æœ‰æ ‡ç­¾çš„è¡Œ
df_lab = df_all[df_all["label"].isin([0, 1])].copy()
if df_lab.empty:
    st.error("æ²¡æœ‰å¯ç”¨æ ‡ç­¾ï¼ˆlabel ä¸º 0/1ï¼‰çš„æ ·æœ¬ã€‚")
    st.stop()

# ç‰©ç†ç‰¹å¾ç™½åå•ï¼ˆä¸åŒ…å«è·ç¦»ï¼‰
feature_cols = [c for c in CANON_ORDER if c in df_lab.columns]  # period,duration,depth,prad,srad,steff

# å¼ºåˆ¶æ•°å€¼åŒ–ï¼ˆéæ•°å€¼â†’NaNï¼‰
num_feats = df_lab[feature_cols].apply(pd.to_numeric, errors="coerce")

# ä¸¢æ‰æ•´åˆ—å…¨ç¼ºå¤±çš„ç‰¹å¾ï¼ˆé¿å… Imputer æ— æ³•è®¡ç®—ä¸­ä½æ•°ï¼‰
all_nan_cols = [c for c in num_feats.columns if num_feats[c].notna().sum() == 0]
if all_nan_cols:
    st.warning(f"è¿™äº›ç‰¹å¾åœ¨å½“å‰æ•°æ®é‡Œå…¨ç¼ºå¤±ï¼Œå·²å¿½ç•¥ï¼š{all_nan_cols}")
    num_feats = num_feats.drop(columns=all_nan_cols)

# mission one-hotï¼ˆä¸ä¿ç•™åŸå§‹ mission åˆ—ï¼‰
if "mission" in df_lab.columns and df_lab["mission"].nunique() > 1:
    df_lab = pd.get_dummies(df_lab, columns=["mission"], drop_first=True)
    mission_cols = [c for c in df_lab.columns if c.startswith("mission_")]
else:
    df_lab = df_lab.drop(columns=[c for c in ["mission"] if c in df_lab.columns])
    mission_cols = []

# ç»„è£… X / yï¼ˆåªæœ‰ç‰©ç†ç‰¹å¾ + mission one-hotï¼Œä¸å«ä»»ä½•è·ç¦»åˆ—ï¼‰
X = pd.concat([num_feats, df_lab[mission_cols]], axis=1).select_dtypes(include=["number"])
y = df_lab["label"].astype(int)

# åŸºæœ¬æ£€æŸ¥
if X.shape[1] == 0:
    st.error("å¯ç”¨çš„ç‰©ç†ç‰¹å¾åˆ—ä¸º 0ã€‚è¯·æ£€æŸ¥ä¸Šä¼ æ•°æ®æˆ–å‡å°‘å¿…éœ€ç‰¹å¾ã€‚")
    st.stop()
if len(X) < 2:
    st.error(f"æ¸…æ´—åå¯è®­ç»ƒæ ·æœ¬æ•°ä¸è¶³ï¼ˆ{len(X)} æ¡ï¼‰ã€‚")
    st.stop()

# åˆ†å±‚ä»…å½“ç±»åˆ«â‰¥2
stratify_y = y if y.nunique() > 1 else None

# è®¡ç®—â€œå¯è¡Œâ€çš„ test_sizeï¼šè‡³å°‘ 1 æ¡è®­ç»ƒ + 1 æ¡æµ‹è¯•
n = len(X)
n_test = max(1, int(round(n * test_size)))
n_test = min(n - 1, n_test)
test_size_eff = n_test / n

# åˆ‡åˆ†ï¼šåˆ†å±‚å¤±è´¥å°±é™çº§éåˆ†å±‚
try:
    X_tr, X_te, y_tr, y_te = train_test_split(
        X, y, test_size=test_size_eff, random_state=rs, stratify=stratify_y
    )
except ValueError:
    X_tr, X_te, y_tr, y_te = train_test_split(
        X, y, test_size=test_size_eff, random_state=rs, stratify=None
    )

# ---------------- è®­ç»ƒ ----------------
# å…ˆç¼ºå¤±å€¼æ’è¡¥ï¼Œå†æ ‡å‡†åŒ–ï¼Œå†éšæœºæ£®æ—
model = make_pipeline(
    SimpleImputer(strategy="median"),
    StandardScaler(),
    RandomForestClassifier(
        n_estimators=n_estimators, class_weight="balanced",
        random_state=rs, n_jobs=-1
    )
)
model.fit(X_tr, y_tr)

rf = model.named_steps["randomforestclassifier"]
y_proba = model.predict_proba(X_te)[:, 1]

# F1 æœ€ä¼˜é˜ˆå€¼ï¼ˆåœ¨ hold-out ä¸Šå…ˆç»™ä¸€ä¸ªå‚è€ƒå€¼ï¼‰
prec0, rec0, thr0 = precision_recall_curve(y_te, y_proba)
f10 = 2 * prec0 * rec0 / (prec0 + rec0 + 1e-9)
best_idx0 = int(np.nanargmax(f10))
best_thr0 = float(thr0[max(min(best_idx0, len(thr0) - 1), 0)]) if len(thr0) else 0.5

# ---------------- è¯„ä¼°æ¨¡å¼ ----------------
st.subheader("3) Thresholds and indicators")
mode = st.radio(
    "Evaluate on",
    ["Hold-out test set", "All labeled (in-sample)", "5-fold CV (out-of-fold)"],
    index=0, horizontal=True
)

use_mode = mode
if mode == "5-fold CV (out-of-fold)" and (len(X) < 5 or y.nunique() < 2):
    st.warning("æ ·æœ¬ä¸è¶³ä»¥åš 5-fold CV æˆ–åªæœ‰ä¸€ä¸ªç±»åˆ«ï¼Œè‡ªåŠ¨æ”¹ä¸ºï¼šAll labeled (in-sample)")
    use_mode = "All labeled (in-sample)"

if use_mode == "Hold-out test set":
    y_eval = y_te
    proba_eval = y_proba
elif use_mode == "All labeled (in-sample)":
    y_eval = y
    proba_eval = model.predict_proba(X)[:, 1]
else:  # 5-fold CV
    base_pipe = make_pipeline(
        StandardScaler(),
        RandomForestClassifier(
            n_estimators=n_estimators, class_weight="balanced",
            random_state=rs, n_jobs=-1
        )
    )
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=rs) if y.nunique() > 1 else None
    if skf is None:
        # ä¿é™©å…œåº•ï¼šç±»åˆ«ä¸º 1 æ—¶é€€å› in-sample
        y_eval = y
        proba_eval = model.predict_proba(X)[:, 1]
        st.warning("åªæœ‰ä¸€ä¸ªç±»åˆ«ï¼ŒCV é€€å› in-sample è¯„ä¼°ã€‚")
    else:
        proba_eval = cross_val_predict(base_pipe, X, y, cv=skf, method="predict_proba")[:, 1]
        y_eval = y

# ç”¨ proba_eval + é˜ˆå€¼åšæ‰€æœ‰æŒ‡æ ‡/æ›²çº¿/æ··æ·†çŸ©é˜µ
prec, rec, thr = precision_recall_curve(y_eval, proba_eval)
f1 = 2 * prec * rec / (prec + rec + 1e-9)
best_idx = int(np.nanargmax(f1))
best_thr = float(thr[max(min(best_idx, len(thr) - 1), 0)]) if len(thr) else best_thr0

sel_thr = st.slider("Decision threshold", 0.0, 1.0, best_thr, 0.01)
y_pred_eval = (proba_eval >= sel_thr).astype(int)

# æ··æ·†çŸ©é˜µå›ºå®š labels=[0,1]ï¼Œé˜²æ­¢ 1x1 çš„æƒ…å†µ ravel å¤±è´¥
cm = confusion_matrix(y_eval, y_pred_eval, labels=[0, 1])
TN, FP, FN, TP = cm.ravel()
acc = (TP + TN) / cm.sum()
P = TP / (TP + FP + 1e-9)
R = TP / (TP + FN + 1e-9)
F1 = 2 * P * R / (P + R + 1e-9)

# æŒ‡æ ‡å¡ç‰‡
kpi_grid({
    "Accuracy": f"{acc:.3f}",
    "Precision": f"{P:.3f}",
    "Recall": f"{R:.3f}",
    "F1": f"{F1:.3f}",
})

# å››è”å›¾ï¼ˆä¼ å…¥ï¼šy_eval/y_pred_eval/proba_evalï¼‰
fig = build_dashboard_fig(rf, X.columns.tolist(), y_eval, y_pred_eval, proba_eval)
st.pyplot(fig, clear_figure=True)


# ---------------- ç»“æœæµè§ˆ / ä¸‹è½½ ----------------
st.subheader("4) Browse / Download Results")
# è¿™é‡Œä»ç„¶å±•ç¤º hold-out çš„ç»Ÿè®¡ï¼ˆæ›´è´´è¿‘â€œéƒ¨ç½²åé¢„æµ‹æµè§ˆâ€ï¼‰
pred_df = pd.DataFrame({
    "y_true": y_te.values,
    "proba": y_proba,
    "pred": (y_proba >= sel_thr).astype(int)
}, index=y_te.index).join(X_te)

mission_cols = [c for c in pred_df.columns if c.startswith("mission_")]
if mission_cols:
    ms = st.multiselect("Filter by mission", mission_cols, default=mission_cols)
    mask = pred_df[ms].sum(axis=1) > 0
    view = pred_df[mask]
else:
    view = pred_df

topk = st.slider("Top-N by probability", 10, 200, 50, 10)
st.dataframe(view.sort_values("proba", ascending=False).head(topk))
st.download_button(
    "Download current view CSV",
    data=view.sort_values("proba", ascending=False).to_csv(index=False).encode("utf-8"),
    file_name="predictions_view.csv",
    mime="text/csv"
)

